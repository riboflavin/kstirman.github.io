<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Statistics on dremio | reimagining data analytics for the modern world</title>
    <link>http://www.dremio.com/categories/statistics/index.xml</link>
    <description>Recent content in Statistics on dremio | reimagining data analytics for the modern world</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <atom:link href="http://www.dremio.com/categories/statistics/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Parsing EPA vehicle data for linear correlations in MPG ratings</title>
      <link>http://www.dremio.com/blog/parsing-epa-vehicle-data-for-linear-correlations-in-mpg-ratings/</link>
      <pubDate>Thu, 11 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>http://www.dremio.com/blog/parsing-epa-vehicle-data-for-linear-correlations-in-mpg-ratings/</guid>
      <description>&lt;p&gt;In &lt;a href=&#34;http://www.dremio.com/blog/calculating-pearsons-r-using-a-custom-sql-function/&#34;&gt;the previous day&amp;rsquo;s post&lt;/a&gt; I
demonstrated how to code a custom aggregate function that can process two sets of data points into their corresponding
Pearson&amp;rsquo;s &lt;em&gt;r&lt;/em&gt; value, which is a useful indicator of variable correlation. Today I&amp;rsquo;m going to put that function to the
test on this &lt;a href=&#34;https://www.fueleconomy.gov/feg/download.shtml&#34;&gt;EPA data set&lt;/a&gt; that contains information about vehicles
manufactured from model years 1984 to 2017. The two questions I&amp;rsquo;d like to answer are: 1.) Does the combined MPG rating
for a car correlate with model year? and 2.) How does an engine&amp;rsquo;s displacement affect the combined MPG rating?&lt;/p&gt;

&lt;p&gt;To begin with, I&amp;rsquo;m going to create two views that average over combined MPG for each of the other variables of interest.
These are constructed as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;CREATE VIEW year_mpg AS
     SELECT CAST(`year` AS FLOAT) `year`, AVG(CAST(comb08 AS FLOAT)) mpg
       FROM dfs.`/Users/ngriffith/Downloads/vehicles.csvh`
   GROUP BY `year`
   ORDER BY `year`;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;helps answer the first question about model years, while&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;CREATE VIEW displacement_mpg AS
     SELECT CAST(displ AS FLOAT) displacement, AVG(CAST(comb08 AS FLOAT)) mpg
       FROM dfs.`/Users/ngriffith/Downloads/vehicles.csvh`
      WHERE displ NOT LIKE &#39;&#39;
        AND displ NOT LIKE &#39;NA&#39;
   GROUP BY displ
   ORDER BY displacement;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;will allow us tackle the second one about engine sizes.&lt;/p&gt;

&lt;p&gt;The first view looks like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; SELECT * FROM year_mpg;
+---------+---------------------+
|  year   |         mpg         |
+---------+---------------------+
| 1984.0  | 19.881873727087576  |
| 1985.0  | 19.808348030570254  |
| 1986.0  | 19.550413223140495  |
| 1987.0  | 19.228548516439453  |
| 1988.0  | 19.328318584070797  |
| 1989.0  | 19.12575888985256   |
| 1990.0  | 19.000927643784788  |
| 1991.0  | 18.825971731448764  |
| 1992.0  | 18.86262265834077   |
| 1993.0  | 19.104300091491307  |
| 1994.0  | 19.0122199592668    |
| 1995.0  | 18.797311271975182  |
| 1996.0  | 19.584734799482536  |
| 1997.0  | 19.429133858267715  |
| 1998.0  | 19.51847290640394   |
| 1999.0  | 19.61150234741784   |
| 2000.0  | 19.526190476190475  |
| 2001.0  | 19.479692645444565  |
| 2002.0  | 19.168205128205127  |
| 2003.0  | 19.00095785440613   |
| 2004.0  | 19.067736185383243  |
| 2005.0  | 19.193825042881645  |
| 2006.0  | 18.95923913043478   |
| 2007.0  | 18.97868561278863   |
| 2008.0  | 19.27632687447346   |
| 2009.0  | 19.74070945945946   |
| 2010.0  | 20.601442741208295  |
| 2011.0  | 21.10353982300885   |
| 2012.0  | 21.93755420641804   |
| 2013.0  | 23.253164556962027  |
| 2014.0  | 23.70114006514658   |
| 2015.0  | 24.214953271028037  |
| 2016.0  | 24.84784446322908   |
| 2017.0  | 23.571428571428573  |
+---------+---------------------+
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Yup, it definitely looks like there&amp;rsquo;s a trend toward higher MPG. But let&amp;rsquo;s calculate the &lt;em&gt;r&lt;/em&gt; value:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; SELECT PCORRELATION(`year`, mpg) FROM year_mpg;
Error: SYSTEM ERROR: SchemaChangeException: Failure while materializing expression.
Error in expression at index -1.  Error: Missing function implementation: [pcorrelation(FLOAT4-REQUIRED,
FLOAT8-OPTIONAL)].  Full expression: --UNKNOWN EXPRESSION--.
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Oops! We got an error message instead of an &lt;em&gt;r&lt;/em&gt; value. That&amp;rsquo;s because my &lt;code&gt;PCORRELATION()&lt;/code&gt; function expects two variables
that are nullable (&amp;lsquo;optional&amp;rsquo;), but the first one that&amp;rsquo;s getting passed is non-nullable (&amp;lsquo;required&amp;rsquo;). This situation is
what led to the creation of &lt;a href=&#34;http://www.dremio.com/blog/managing-variable-type-nullability/&#34;&gt;this earlier article and its associated
functions&lt;/a&gt; for stripping and adding nullability to
variables. The &lt;code&gt;ADD_NULL_FLOAT()&lt;/code&gt; custom function from that piece is exactly what we need to turn &lt;code&gt;`years `&lt;/code&gt; into a
variable type that &lt;code&gt;PCORRELATION()&lt;/code&gt; can accept.&lt;/p&gt;

&lt;p&gt;So let&amp;rsquo;s try this again:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; SELECT PCORRELATION(ADD_NULL_FLOAT(`year`), mpg) FROM year_mpg;
+---------------------+
|       EXPR$0        |
+---------------------+
| 0.6870535033886027  |
+---------------------+
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Correlation confirmed! It&amp;rsquo;s not the strongest (that would be a value of 1.0), but it&amp;rsquo;s definitely there. Neat!&lt;/p&gt;

&lt;p&gt;Now to take a look at how engine size related. The view I created contains this data:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; SELECT * FROM displacement_mpg;
+---------------+---------------------+
| displacement  |         mpg         |
+---------------+---------------------+
| 0.0           | 87.5                |
| 0.6           | 39.0                |
| 0.9           | 35.5                |
| 1.0           | 37.5030303030303    |
| 1.1           | 19.916666666666668  |
| 1.2           | 30.81081081081081   |
| 1.3           | 28.904255319148938  |
| 1.4           | 30.658959537572255  |
| 1.5           | 29.439592430858806  |
| 1.6           | 26.48841961852861   |
| 1.7           | 28.842105263157894  |
| 1.8           | 24.91231463571889   |
| 1.9           | 27.038277511961724  |
| 2.0           | 24.032035928143713  |
| 2.1           | 19.28301886792453   |
| 2.2           | 22.07820419985518   |
| 2.3           | 21.026008968609865  |
| 2.4           | 22.373468300479487  |
| 2.5           | 21.628227194492254  |
| 2.6           | 18.123529411764707  |
| 2.7           | 19.88589211618257   |
| 2.8           | 18.463019250253293  |
| 2.9           | 18.772727272727273  |
| 3.0           | 19.428571428571427  |
| 3.1           | 19.72156862745098   |
| 3.2           | 18.25237191650854   |
| 3.3           | 18.54698795180723   |
| 3.4           | 18.473317865429234  |
| 3.5           | 20.02212705210564   |
| 3.6           | 19.188457008244995  |
| 3.7           | 18.107468123861565  |
| 3.8           | 19.115025906735752  |
| 3.9           | 15.588815789473685  |
| 4.0           | 16.738241308793455  |
| 4.1           | 15.873684210526315  |
| 4.2           | 16.05597014925373   |
| 4.3           | 16.590775988286968  |
| 4.4           | 17.094736842105263  |
| 4.5           | 15.566666666666666  |
| 4.6           | 16.6696269982238    |
| 4.7           | 15.282548476454293  |
| 4.8           | 15.813688212927756  |
| 4.9           | 14.355113636363637  |
| 5.0           | 15.2375             |
| 5.2           | 13.063197026022305  |
| 5.3           | 15.203412073490814  |
| 5.4           | 13.902597402597403  |
| 5.5           | 15.16243654822335   |
| 5.6           | 14.0                |
| 5.6           | 14.394736842105264  |
| 5.7           | 14.780718336483933  |
| 5.8           | 11.78125            |
| 5.9           | 11.701183431952662  |
| 6.0           | 14.462686567164178  |
| 6.1           | 15.0                |
| 6.1           | 14.454545454545455  |
| 6.2           | 16.540930979133226  |
| 6.3           | 13.705882352941176  |
| 6.4           | 16.8                |
| 6.5           | 14.81081081081081   |
| 6.6           | 15.0                |
| 6.7           | 13.0                |
| 6.8           | 10.572463768115941  |
| 7.0           | 17.4                |
| 7.4           | 9.75                |
| 8.0           | 12.347826086956522  |
| 8.3           | 11.222222222222221  |
| 8.4           | 15.6                |
+---------------+---------------------+
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Which, after making a similar adjustment using &lt;code&gt;ADD_NULL_FLOAT()&lt;/code&gt;, yields a correlation of:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; SELECT PCORRELATION(ADD_NULL_FLOAT(displacement), mpg) FROM displacement_mpg;
+---------------------+
|       EXPR$0        |
+---------------------+
| -0.679501632464044  |
+---------------------+
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So combined average combined MPG is almost as strongly anti-correlated with engine size as it is correlated with model
year. There&amp;rsquo;s a fairly clear linear dependence in both cases!&lt;/p&gt;

&lt;p&gt;For my next couple articles I&amp;rsquo;ll be digging even deeper into statistical techniques by implementing and testing a Drill
function to calculate the probability of events that follow a Poisson distribution. It&amp;rsquo;s shaping up to be a great
couple of weeks to be reading the Dremio Blog if you&amp;rsquo;re curious about what custom-tuned &amp;lsquo;SQL on anything&amp;rsquo; software can
do in terms of serious analysis.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Calculating Pearson&#39;s r using a custom SQL function</title>
      <link>http://www.dremio.com/blog/calculating-pearsons-r-using-a-custom-SQL-function/</link>
      <pubDate>Wed, 10 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>http://www.dremio.com/blog/calculating-pearsons-r-using-a-custom-SQL-function/</guid>
      <description>&lt;script type=&#34;text/javascript&#34;
 src=&#34;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&#34;&gt;
&lt;/script&gt;

&lt;p&gt;Lately I&amp;rsquo;ve written a lot of custom functions to assist me in my example Drill analyses, but they&amp;rsquo;ve all been of the
same fundamental type: They take one or more columns of a single row and process them into a single output. The &lt;a href=&#34;https://drill.apache.org/docs/develop-custom-functions-introduction/&#34;&gt;Drill
documentation&lt;/a&gt; calls these &amp;ldquo;simple&amp;rdquo; functions.
However there&amp;rsquo;s another class of functions lurking out there&amp;mdash;ones that can accept &lt;em&gt;many&lt;/em&gt; rows of data as input. We
call them &amp;ldquo;aggregate&amp;rdquo; functions.&lt;/p&gt;

&lt;p&gt;If you&amp;rsquo;re an experienced user of SQL, you&amp;rsquo;re already familiar with a few very common aggregate functions like &lt;code&gt;COUNT()&lt;/code&gt;
and &lt;code&gt;SUM()&lt;/code&gt;, but you&amp;rsquo;ve probably never written one of your own. Today we&amp;rsquo;re going to change that!&lt;/p&gt;

&lt;p&gt;As I&amp;rsquo;ve discussed in previous articles Drill already has some built-in statistics functions, but the goal of this post
will be to expand those capabilities even further by implementing an aggregate function to calculate a value called
Pearson&amp;rsquo;s &lt;em&gt;r&lt;/em&gt;. Values for &lt;em&gt;r&lt;/em&gt; vary from +1 to -1, and indicate the degree to which two variables are linearly correlated
or anti-correlated, respectively. An &lt;em&gt;r&lt;/em&gt; value at or near 0 indicates that there is no linear relationship between the
two sets of data points.&lt;/p&gt;

&lt;p&gt;After looking on Wikipedia, the most Drill-friendly equation for Pearson&amp;rsquo;s &lt;em&gt;r&lt;/em&gt; is:&lt;/p&gt;

&lt;p&gt;$$ r = \frac{n \sum x_i y_i - \sum x_i \sum y_i}{ \sqrt{n \sum x_i^2 - \left( \sum x_i \right)^2} \sqrt{n \sum y_i^2 -
\left( \sum y_i \right)^2}} $$&lt;/p&gt;

&lt;p&gt;where \( x_i \) and \( y_i \) are our data points, and \( n \) is the total number of them.&lt;/p&gt;

&lt;p&gt;Once you&amp;rsquo;ve got a Maven project started for your Drill UDF (a guide is available in the &amp;ldquo;Downloading Maven and starting
a new project&amp;rdquo; section of &lt;a href=&#34;http://www.dremio.com/blog/writing-a-custom-sql-function-for-sentiment-analysis/&#34;&gt;this
article&lt;/a&gt;), take a look at the source
for our Pearson&amp;rsquo;s &lt;em&gt;r&lt;/em&gt; function:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;package com.yourgroupidentifier.udf;

import org.apache.drill.exec.expr.DrillAggFunc;
import org.apache.drill.exec.expr.holders.IntHolder;
import org.apache.drill.exec.expr.holders.NullableFloat8Holder;
import org.apache.drill.exec.expr.holders.Float8Holder;

import org.apache.drill.exec.expr.annotations.FunctionTemplate;

import org.apache.drill.exec.expr.annotations.Param;
import org.apache.drill.exec.expr.annotations.Workspace;
import org.apache.drill.exec.expr.annotations.Output;

@FunctionTemplate(
        name = &amp;quot;pcorrelation&amp;quot;,
        scope = FunctionTemplate.FunctionScope.POINT_AGGREGATE,
        nulls = FunctionTemplate.NullHandling.INTERNAL
)

public class PCorrelation implements DrillAggFunc {

    @Param
    NullableFloat8Holder xInput;

    @Param
    NullableFloat8Holder yInput;

    @Workspace
    IntHolder numValues;

    @Workspace
    Float8Holder xSum;

    @Workspace
    Float8Holder ySum;

    @Workspace
    Float8Holder xSqSum;

    @Workspace
    Float8Holder ySqSum;

    @Workspace
    Float8Holder xySum;

    @Output
    Float8Holder output;

    public void setup() {
        // Initialize values
        numValues.value = 0;
        xSum.value = 0;
        ySum.value = 0;
        xSqSum.value = 0;
        ySqSum.value = 0;
        xySum.value = 0;
    }

    public void reset() {
        // Initialize values
        numValues.value = 0;
        xSum.value = 0;
        ySum.value = 0;
        xSqSum.value = 0;
        ySqSum.value = 0;
        xySum.value = 0;
    }

    public void add() {

        // Only proceed if both floats aren&#39;t nulls
        if( (xInput.isSet == 1) || (yInput.isSet == 1) ) {

            numValues.value++;

            xSum.value += xInput.value;
            ySum.value += yInput.value;

            xSqSum.value += xInput.value * xInput.value;
            ySqSum.value += yInput.value * yInput.value;

            xySum.value += xInput.value * yInput.value;
        }

    }

    public void output() {

        float n = numValues.value;

        double x = xSum.value;
        double y = ySum.value;

        double x2 = xSqSum.value;
        double y2 = ySqSum.value;

        double xy = xySum.value;

        output.value = (n*xy - x*y)/(Math.sqrt(n*x2 - x*x)*Math.sqrt(n*y2 - y*y));
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Yes, that&amp;rsquo;s a chunk of code&amp;mdash;but it&amp;rsquo;s mostly this long because it takes a lot of variables to accomplish the &lt;em&gt;r&lt;/em&gt;
calculation. Anyway, let&amp;rsquo;s talk about some differences between this aggregate function and the simple ones we&amp;rsquo;ve been
writing up until now.&lt;/p&gt;

&lt;p&gt;First, up in the function template the scope changes from &lt;code&gt;SIMPLE&lt;/code&gt; to &lt;code&gt;POINT_AGGREGATE&lt;/code&gt;, while the null handling is set
to &lt;code&gt;INTERNAL&lt;/code&gt; instead of &lt;code&gt;NULL_IF_NULL&lt;/code&gt;. This is because aggregate functions need to determine on their own how to
process null inputs, rather than let Drill handle it for them as we can do for most simple functions. You&amp;rsquo;ll also notice
a new annotation, &lt;code&gt;@Workspace&lt;/code&gt;, which is used before variables that assist in the calculation of the result as the
function moves through each row.&lt;/p&gt;

&lt;p&gt;Another obvious difference is that aggregate functions implement a different set of methods than simple ones. The
&lt;code&gt;setup()&lt;/code&gt; method remains the same, but &lt;code&gt;output()&lt;/code&gt; takes the place of &lt;code&gt;eval()&lt;/code&gt;. For each row that&amp;rsquo;s processed &lt;code&gt;add()&lt;/code&gt; is
called, and &lt;code&gt;reset()&lt;/code&gt; is used to determine what the function does when it hits a new set of rows.&lt;/p&gt;

&lt;p&gt;In the next article, I&amp;rsquo;ll take this new &lt;code&gt;PCORRELATION()&lt;/code&gt; function out for a spin on some vehicle data from the EPA.&lt;/p&gt;

&lt;p&gt;(OK, yes, pun very much intended that time.)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Performing basic statistics operations on Twitter data</title>
      <link>http://www.dremio.com/blog/performing-basic-statistics-operations-on-Twitter-data/</link>
      <pubDate>Thu, 03 Dec 2015 00:00:00 +0000</pubDate>
      
      <guid>http://www.dremio.com/blog/performing-basic-statistics-operations-on-Twitter-data/</guid>
      <description>&lt;p&gt;I&amp;rsquo;ve used Drill&amp;rsquo;s &lt;code&gt;AVG()&lt;/code&gt; function quite a bit previously, but in this post I&amp;rsquo;d like to point out some other basic
statistics operations you can do in Drill.&lt;/p&gt;

&lt;p&gt;For my trial data I&amp;rsquo;m going to reference my trusty corpus of nearly 52,000 tweets pulled from Twitter&amp;rsquo;s streaming API,
and with it I&amp;rsquo;m going to try to get a sense of how long people prefer to make their Twitter profile&amp;rsquo;s &amp;lsquo;real name.&amp;rsquo; To do
this I&amp;rsquo;ll take an average, a standard deviation, and a median of the length of this field in the data.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ll start with the old news, and take an average:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; SELECT AVG(LENGTH(t.`user`.name)) namelength FROM dfs.`/path/to/tweets.small.json` t;
+--------------------+
|     namelength     |
+--------------------+
| 9.995608290315124  |
+--------------------+
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Nothing to it, right? Drill also has a built-in function taking the standard deviation, which works in exactly the same way:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; SELECT STDDEV(LENGTH(t.`user`.name)) namelength FROM dfs.`/path/to/tweets.small.json` t;
+--------------------+
|     namelength     |
+--------------------+
| 4.981551245459341  |
+--------------------+
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There&amp;rsquo;s no built-in function for finding the median, but we can work it out by issuing a couple queries. First we&amp;rsquo;ll use
a &lt;code&gt;COUNT()&lt;/code&gt; to return the total number of rows, and then use that result to pull a value from the middle of the sorted
set of data.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; SELECT COUNT(*) FROM dfs.`/path/to/tweets.small.json` t;
+---------+
| EXPR$0  |
+---------+
| 51916   |
+---------+
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; SELECT LENGTH(t.`user`.name) namelength FROM dfs.`/path/to/tweets.small.json` t ORDER BY namelength LIMIT 1 OFFSET 25958;
+-------------+
| namelength  |
+-------------+
| 10          |
+-------------+
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Applying these statistical methods to found data via Drill is an easy task, and it&amp;rsquo;s part of what makes it an attractive
piece of software for those wanting to efficiently explore new sets of information.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>