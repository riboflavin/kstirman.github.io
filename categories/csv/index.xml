<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Csv on dremio | reimagining data analytics for the modern world</title>
    <link>localhost:1313</link>
    <description>Recent content in Csv on dremio | reimagining data analytics for the modern world</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <atom:link href="#ZgotmplZ" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Using a SQL JOIN on two CSV files</title>
      <link>localhost:1313</link>
      <pubDate>Tue, 19 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>localhost:1313</guid>
      <description>&lt;p&gt;One of Drill&amp;rsquo;s great strengths is its ability to unite sets of information found in different places. In today&amp;rsquo;s article
I&amp;rsquo;ll provide a quick example of this functionality by showing you how to you use Drill to quickly improve the interface
to some found data.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ll start with the interesting but strangely formatted business-centered census data that we used in the &lt;a href=&#34;http://www.dremio.com/blog/converting-csv-file-data-to-kudu-storage/&#34;&gt;last
post&lt;/a&gt; (available on
&lt;a href=&#34;https://www.census.gov/econ/cbp/download/&#34;&gt;this site&lt;/a&gt; as a 14.3 MB zip file). As you&amp;rsquo;ll recall, our command to query
the state, county, and industry codes, along with the number of establishments, yielded results in the following format:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;+-----------+----------+---------+------+
| fipstate  | fipscty  |  naics  | est  |
+-----------+----------+---------+------+
| 55        | 107      | 321113  | 1    |
| 48        | 185      | 51213/  | 1    |
| 39        | 135      | 42491/  | 6    |
| 04        | 027      | 4411//  | 30   |
| 08        | 085      | 541870  | 1    |
| 26        | 061      | 51----  | 17   |
| 28        | 049      | 519///  | 3    |
| 48        | 139      | 48849/  | 3    |
| 22        | 073      | 4853//  | 3    |
| 48        | 139      | 424910  | 10   |
+-----------+----------+---------+------+
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It&amp;rsquo;s great to have data with this level of granularity, but the FIPS codes that the file uses to identify the state and
county are far from intuitive. Thankfully we can use Drill in combination with this &lt;a href=&#34;https://github.com/hadley/data-counties/blob/master/county-fips.csv&#34;&gt;lovely CSV
file&lt;/a&gt; from Github user &amp;lsquo;hadley&amp;rsquo; to make the data
more user-friendly. (Remember to rename both files as &amp;lsquo;.csvh&amp;rsquo; so Drill knows to pick up the column names!)&lt;/p&gt;

&lt;p&gt;Because Drill effectively treats each file as a separate table, we can gain access to human readable state and county
names by performing an SQL JOIN across the files.&lt;/p&gt;

&lt;p&gt;That handy file from Github has a format like&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;+-----------------------+--------+--------------+-------------+
|        county         | state  | county_fips  | state_fips  |
+-----------------------+--------+--------------+-------------+
| Aleutians East        | AK     | 13           | 2           |
| Aleutians West        | AK     | 16           | 2           |
| Anchorage             | AK     | 20           | 2           |
| Bethel                | AK     | 50           | 2           |
| Bristol Bay           | AK     | 60           | 2           |
| Denali                | AK     | 68           | 2           |
| Dillingham            | AK     | 70           | 2           |
| Fairbanks North Star  | AK     | 90           | 2           |
| Haines                | AK     | 100          | 2           |
| Juneau                | AK     | 110          | 2           |
+-----------------------+--------+--------------+-------------+
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;so a simple query that brings state and county names to the census data using a JOIN is:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  SELECT t2.state, t2.county, SUM(CAST(t1.est AS INT)) `total establishments`
    FROM dfs.`/path/to/cbp13co.csvh` t1
    JOIN dfs.`/path/to/county-fips.csvh` t2
      ON t1.fipstate = t2.state_fips
     AND t1.fipscty = t2.county_fips
GROUP BY t2.state, t2.county
ORDER BY `total establishments`
    DESC LIMIT 10;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Which, for the curious, produces the following output:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;+--------+--------------+-----------------------+
| state  |    county    | total establishments  |
+--------+--------------+-----------------------+
| TX     | Harris       | 571756                |
| TX     | Dallas       | 374670                |
| NY     | Suffolk      | 291970                |
| TX     | Tarrant      | 232484                |
| MI     | Oakland      | 230154                |
| GA     | Fulton       | 203028                |
| MI     | Wayne        | 190806                |
| NY     | Westchester  | 189820                |
| TX     | Travis       | 186236                |
| MO     | St. Louis    | 184326                |
+--------+--------------+-----------------------+
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Cool! (And, no, I have no idea why Harris county, Texas is apparently the business capitol of the United States.)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>SQL queries on CSV files with column headers</title>
      <link>localhost:1313</link>
      <pubDate>Mon, 23 Nov 2015 00:00:00 +0000</pubDate>
      
      <guid>localhost:1313</guid>
      <description>&lt;p&gt;A new feature of Drill 1.3.0 is the ability to query CSV files using the column names listed in the file&amp;rsquo;s header.&lt;/p&gt;

&lt;p&gt;As an example, let&amp;rsquo;s look at &lt;a href=&#34;http://introcs.cs.princeton.edu/java/data/olympic-medals2012.csv&#34;&gt;this CSV formatted file&lt;/a&gt;
of countries that participated in the 2012 Summer Olympics. Before we begin, rename the file so that it ends in &amp;lsquo;.csvh&amp;rsquo;
instead of &amp;lsquo;.csv&amp;rsquo;. The extension change tells Drill to parse the header of the CSV file, which means we can use the
in-file identifiers for column names when we construct our queries.&lt;/p&gt;

&lt;p&gt;So now we can ask for the 10 countries with the most medals by entering:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; SELECT `Country.name` AS Country, CAST(Total AS INT) `Total Medals` FROM dfs.`/path/to/olympic-medals2012.csvh` ORDER BY `Total Medals` DESC LIMIT 10;
+--------------+---------------+
|   Country    | Total Medals  |
+--------------+---------------+
| US           | 104           |
| China        | 88            |
| Russia       | 82            |
| UK           | 65            |
| Germany      | 44            |
| Japan        | 38            |
| Australia    | 35            |
| France       | 34            |
| Italy        | 28            |
| South Korea  | 28            |
+--------------+---------------+
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can also enable header parsing for any extension (including regular .csv files) by using the Drill Web Console to
edit the JSON of a storage plugin. You can open the console by running &amp;lsquo;drill-embedded&amp;rsquo; and going to
&lt;a href=&#34;http://localhost:8047&#34;&gt;http://localhost:8047&lt;/a&gt; in a browser. Once you&amp;rsquo;ve loaded the page, go to &amp;ldquo;Storage&amp;rdquo; at the top and click &amp;ldquo;Update&amp;rdquo; next to
(for example) the &amp;lsquo;dfs&amp;rsquo; plugin for the local file system. To enable header parsing for a file type we need to add the
key-value pair &lt;code&gt;&amp;quot;extractHeader&amp;quot;: true&lt;/code&gt; to an entry in the &amp;ldquo;formats&amp;rdquo; section of the file. For instance, if we change the
plugin so that tab separated (.tsv) files now have their headers read, then the section for that format would read:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;...
    &amp;quot;tsv&amp;quot;: {
      &amp;quot;type&amp;quot;: &amp;quot;text&amp;quot;.
      &amp;quot;extensions&amp;quot;: [
        &amp;quot;tsv&amp;quot;
      ],
      &amp;quot;extractHeader&amp;quot;: true,
      &amp;quot;delimiter&amp;quot;: &amp;quot;\t&amp;quot;
    },
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Drill was &lt;em&gt;already&lt;/em&gt; an amazing tool for querying text files. But header parsing makes it even better!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Running SQL Queries on CSV Files Using Apache Drill</title>
      <link>localhost:1313</link>
      <pubDate>Tue, 13 Oct 2015 00:00:00 +0000</pubDate>
      
      <guid>localhost:1313</guid>
      <description>&lt;p&gt;If you find a large data store on the web that you&amp;rsquo;re interested in, chances are good that it&amp;rsquo;ll be available for
download as a dump to a CSV file. The CSV format definitely isn&amp;rsquo;t the most sophisticated data storage method around, but
it&amp;rsquo;s common, relatively intuitive for humans to read, and simple to import and export from spreadsheet software like
Excel and LibreOffice. Many of us, however, might want to quickly integrate a CSV data set with an existing database
system (like Hadoop or MongoDB) that&amp;rsquo;s already in place. Or, you may simply prefer to have an SQL interface to the data
instead of suffering through an officeware GUI. In both these cases, Apache Drill is the answer.&lt;/p&gt;

&lt;p&gt;For this article I&amp;rsquo;ll focus on the second use scenario as implemented on a single machine running OS X. The data I&amp;rsquo;ll be
looking at comes from a CSV dump of the confirmed planets from NASA&amp;rsquo;s Exoplanet Archive, which is freely available via
&lt;a href=&#34;http://exoplanetarchive.ipac.caltech.edu&#34;&gt;this site&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;To get started, we&amp;rsquo;ll need to install Apache Drill. First, go download and install the Java SE SD Development Kit if you
don&amp;rsquo;t already have it. Then open a terminal and download Drill using the following command&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ curl -o apache-drill.tar.gz http://getdrill.org/drill/download/apache-drill-1.1.0.tar.gz
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next make an install folder (in this case we&amp;rsquo;re placing it in the home directory)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ mkdir ~/apache-drill
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and then unpack the file and move the resulting directory&amp;rsquo;s contents to the install location&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ tar xzvf apache-drill-1.1.0.tar.gz
$ mv apache-drill-1.1.0/* ~/apache-drill
$ rm -rf apache-drill-1.1.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now it&amp;rsquo;s easy to launch the single-machine version of Apache Drill with&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ~/apache-drill/bin/drill-embedded
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;From here on out we&amp;rsquo;ll be playing with the file &amp;lsquo;planets.csv&amp;rsquo; that we downloaded from the NASA site. Before the real
number-crunching fun begins, however, you&amp;rsquo;ll need to comment out line 382 of the file (assuming you dumped all of the
columns available). This just hides the names of each field, which would only get in the way since Apache Drill
currently deals directly with the column numbers of a CSV file (this may change in a future release).&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s test things out with this simple query that shows the number of planets in 10 star systems from the data set:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; SELECT columns[1] AS `system name`, columns[4] AS `number of planets` FROM dfs.`/Users/nategri/dremio/playdata/planets.csv` LIMIT 20;
+----------------------------+--------------------+
|        system name         | number of planets  |
+----------------------------+--------------------+
| 11 Com                     | 1                  |
| 11 UMi                     | 1                  |
| 14 And                     | 1                  |
| 14 Her                     | 1                  |
| 16 Cyg B                   | 1                  |
| 18 Del                     | 1                  |
| 1RXS J160929.1-210524      | 1                  |
| 24 Sex                     | 2                  |
| 24 Sex                     | 2                  |
| 2MASS J01225093-2439505    | 1                  |
| 2MASS J02192210-3925225    | 1                  |
| 2MASS J04414489+2301513    | 1                  |
| 2MASS J12073346-3932539    | 1                  |
| 2MASS J19383260+4603591    | 1                  |
| 2MASS J21402931+1625183 A  | 1                  |
| 30 Ari B                   | 1                  |
| 4 UMa                      | 1                  |
| 42 Dra                     | 1                  |
| 47 UMa                     | 3                  |
| 47 UMa                     | 3                  |
+----------------------------+--------------------+
20 rows selected (0.141 seconds)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Our solar system has 8 planets, but it seems like a lot of these only have 1 or 2. Let&amp;rsquo;s run another query to get
the average number of planets (note: I&amp;rsquo;m using CAST here to convert the strings to floats).&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; SELECT AVG(CAST(columns[4] AS float)) AS `avg num of planets` FROM dfs.`/Users/nategri/dremio/playdata/planets.csv`;
+---------------------+
| avg num of planets  |
+---------------------+
| 2.134249471458774   |
+---------------------+
1 row selected (0.15 seconds)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Yes, that is certainly far less than 8. So is our solar system a freak? Well, probably not. It&amp;rsquo;s easy to imagine that
bigger planets are simply easier to detect, and if this is the case (spoiler: this definitely the case) then the average
mass of planets in systems with only one detected body ought to be quite a bit bigger than those with more. We can test
our &amp;ldquo;hypothesis&amp;rdquo; (that we know to be true) a with a more complex query:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; SELECT columns[4] AS `num planets`, AVG(CAST(columns[101] AS float)) AS `avg planet mass`, COUNT(DISTINCT columns[1]) AS `num star systems` FROM dfs.`/Users/nategri/dremio/playdata/planets.csv` WHERE columns[101] &amp;lt;&amp;gt; &#39;&#39; GROUP BY &amp;gt; columns[4] ORDER BY CAST(columns[4] AS float);
+--------------+---------------------+-------------------+
| num planets  |   avg planet mass   | num star systems  |
+--------------+---------------------+-------------------+
| 1            | 954.3903533472983   | 332               |
| 2            | 631.1303849087407   | 50                |
| 3            | 460.048579923199    | 24                |
| 4            | 542.5327862175182   | 11                |
| 5            | 158.82839210055494  | 8                 |
| 6            | 7.8500000437100725  | 1                 |
+--------------+---------------------+-------------------+
6 rows selected (0.801 seconds)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Indeed, systems with one detected planet dominate the data set, and the average mass of their planets (in units of
Jupiter masses) is &lt;em&gt;far&lt;/em&gt; higher than that of systems with more planets. Apache Drill is amazing for exactly this kind of
work: spotting and verifying features in found data sets in a rapid, interactive fashion.&lt;/p&gt;

&lt;p&gt;Anyway that&amp;rsquo;s it for this tutorial. Happy Drilling!&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>